:imagesdir: ../../assets/images
include::../style.adoc[]



== Kafka Basics - Consumer (how data gets out)
A Kafka Consumer reads messages from Kafka topics and hands them to your application code for processing. The consumer is the component that:

* Subscribes to one or more topics,

* Fetches records from assigned partitions,

* Tracks offsets (positions) to know what’s been processed,

* Coordinates with other consumers via consumer groups for parallelism and fault tolerance.

*A consumer can read data from any offset within a topic partition. In most cases, a consumer advances its offset linearly, but it could start at any offset and read messages in any order. 

* The consumer will typically “commit” its offset back to the  Kafka cluster so the consumer can resume from where it left off, for example, in case it restarts.

=== Running a Consumer
* In the lower terminal, login to the OpenShift cluster using the following command. use the image:common/clipboard.png[width=30px] icon to copy.
+
[source,sh,role="execute",subs=attributes+]
----
oc login --insecure-skip-tls-verify=false -u {user_name} -p {password} {openshift_api_url}
----

* Run the consumer in the lower terminal
+
[source,sh,role="execute",subs=attributes+]
----
oc run -n kafka-{user_name} demo-consumer --rm -it --restart=Never \
  --image=registry.redhat.io/amq-streams/kafka-40-rhel9:3.0.0 -- \
  bash -lc '/opt/kafka/bin/kafka-console-consumer.sh --bootstrap-server kafka-kafka-bootstrap:9092 --topic demo --group demo-group --from-beginning --property print.key=true --property print.partition=true --property key.separator=" | "'
----



* Observe that the messages that the producer had sent earlier appear in the consumer terminal, indicating that they are being consumed. 


* Type more messages in the producer terminal and observe them being consumed in the consumer terminal.

* Since we are not providing a key, the messages *might* get distributed across partitions and the ordering is not guaranteed if that is the case. We will see how partitions and keys can help us with guaranteed ordering in the next section.
+
NOTE: Since we are sending very few messages, there is chance that all the messages might end up in the same partition. But in real world, there would be thousand of messages per second and without a key, the messages might end up in different partitions.

* Navigate to the https://amq-streams-console-{user_name}.{openshift_cluster_subdomain}/kafka[streams console, window="console"] > Consumer groups. Click on the *demo-group* consumer group to see the details. 
+
image::m1/console_demo-group.png[]

* Each consumer belongs to a consumer group, a list of consumer instances that ensures fault tolerance and scalable message processing. We will learn about consumer groups in detail in the next section.

* Click on the only consumer in the group (consumer ID: console-consumer) to see the details. When a consumer group contains only one consumer, that consumer is responsible for processing all messages of all partitions.
+
image::m1/console_consumer.png[]

* Click on the any partition which has messages consumed(non zero values under Committed and End Offset column) to see the details.
+
image::m1/console_consumed_partition.png[]

* You should be able to see the messages consumed by the consumer from that partition.
+
image::m1/console_consumed_partition_messages.png[]

=== Up Next
Now that we have looked at the basic producer and consumer, about how ordering of messages sent by the producer can be achieved using partitions and keys in the next section.