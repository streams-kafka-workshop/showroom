:imagesdir: ../../assets/images
include::../style.adoc[]



== Kafka Basics - Producer (how data gets into Kafka)

A Kafka Producer is a client application responsible for writing data to a Kafka cluster. These applications send messages, which are typically key-value pairs, into topics within the Kafka cluster.

=== Core Functionality and API:
* API: Producers interact with Kafka through the KafkaProducer API. Producers can be in written in a variety of languages such as Java,  Python, Go, JavaScript, and .NET.

* Producers publish messages to a topic, which appends each message to the end of a partition. When a producer sends a message:
** If a key is provided, Kafka uses its hash to choose the partition.
**If no key is provided, Kafka distributes messages evenly (round-robin) across partitions.

In short, producers are a flexible and powerful way to send data efficiently and reliably while abstracting away much of the underlying distributed system complexities

=== Running the Producer
. Run the basic producer in the upper terminal
+
[source,sh,role="execute",subs=attributes+]
----
oc run -n kafka-{user_name} demo-producer --rm -it --restart=Never \
  --image=registry.redhat.io/amq-streams/kafka-40-rhel9:3.0.0 -- \
  bash -lc '/opt/kafka/bin/kafka-console-producer.sh --bootstrap-server kafka-kafka-bootstrap:9092 --topic demo'
----

. Type the below messages as soon as the producer is ready in the upper terminal. Each line you type is sent as a separate message to the Kafka topic `demo`. Type each word and hit enter.
+
** `welcome`
** `to`
** `the`
** `kafka`
** `workshop`
** `enjoy!`

. Navigate to the https://amq-streams-console-{user_name}.{openshift_cluster_subdomain}/kafka[streams console, window="console"] topics > demo to see the messages you sent.
+
image::m1/console_messages.png[]

* The messages you sent from the producer are successfully received and stored in the Kafka topic `demo`. In the next section, we will learn how to consume these messages from the topic.
